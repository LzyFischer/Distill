Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
wandb: Currently logged in as: vjd5zr to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /sfs/weka/scratch/vjd5zr/project/distill/wandb/run-20250701_002950-ctju6j4o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mistralai/Mistral-7B-Instruct-v0.3_google/gemma-7b-it_20250701-002949
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vjd5zr/multi%E2%80%91student%E2%80%91date
wandb: üöÄ View run at https://wandb.ai/vjd5zr/multi%E2%80%91student%E2%80%91date/runs/ctju6j4o
local rank = 0 device = cuda
Loading tokenizer & frozen backbone ‚Ä¶
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:02<00:04,  2.18s/it]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:04<00:02,  2.02s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.86s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.92s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.49s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:03,  1.72s/it]Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:05<00:01,  1.78s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:06<00:00,  1.39s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:06<00:00,  1.50s/it]
Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Building two LoRA students ‚Ä¶
trainable params: 3,407,872 || all params: 7,251,431,424 || trainable%: 0.0470
trainable params: 3,211,264 || all params: 8,540,892,160 || trainable%: 0.0376
Epoch 1:   0%|          | 0/49 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/49 [00:01<?, ?it/s, CE1=1.243, CE2=3.849, KL=11.656, loss=6.2629]Epoch 1:   2%|‚ñè         | 1/49 [00:01<01:20,  1.68s/it, CE1=1.243, CE2=3.849, KL=11.656, loss=6.2629]Epoch 1:   2%|‚ñè         | 1/49 [00:02<01:20,  1.68s/it, CE1=0.000, CE2=4.118, KL=0.000, loss=4.1231] Epoch 1:   4%|‚ñç         | 2/49 [00:02<00:56,  1.21s/it, CE1=0.000, CE2=4.118, KL=0.000, loss=4.1231]Epoch 1:   4%|‚ñç         | 2/49 [00:03<00:56,  1.21s/it, CE1=0.968, CE2=2.472, KL=13.469, loss=4.7913]Epoch 1:   6%|‚ñå         | 3/49 [00:03<00:56,  1.24s/it, CE1=0.968, CE2=2.472, KL=13.469, loss=4.7913]Epoch 1:   6%|‚ñå         | 3/49 [00:04<00:56,  1.24s/it, CE1=1.231, CE2=3.396, KL=7.770, loss=5.4093] Epoch 1:   8%|‚ñä         | 4/49 [00:04<00:50,  1.11s/it, CE1=1.231, CE2=3.396, KL=7.770, loss=5.4093]Epoch 1:   8%|‚ñä         | 4/49 [00:05<00:50,  1.11s/it, CE1=0.985, CE2=3.004, KL=11.828, loss=5.1766]Epoch 1:  10%|‚ñà         | 5/49 [00:05<00:50,  1.16s/it, CE1=0.985, CE2=3.004, KL=11.828, loss=5.1766]Epoch 1:  10%|‚ñà         | 5/49 [00:07<00:50,  1.16s/it, CE1=1.022, CE2=2.660, KL=10.586, loss=4.7454]Epoch 1:  12%|‚ñà‚ñè        | 6/49 [00:07<00:50,  1.17s/it, CE1=1.022, CE2=2.660, KL=10.586, loss=4.7454]Epoch 1:  12%|‚ñà‚ñè        | 6/49 [00:08<00:50,  1.17s/it, CE1=0.963, CE2=2.425, KL=13.289, loss=4.7224]Epoch 1:  14%|‚ñà‚ñç        | 7/49 [00:08<00:52,  1.25s/it, CE1=0.963, CE2=2.425, KL=13.289, loss=4.7224]Epoch 1:  14%|‚ñà‚ñç        | 7/49 [00:09<00:52,  1.25s/it, CE1=1.350, CE2=2.955, KL=10.875, loss=5.3977]Epoch 1:  16%|‚ñà‚ñã        | 8/49 [00:09<00:51,  1.26s/it, CE1=1.350, CE2=2.955, KL=10.875, loss=5.3977]Epoch 1:  16%|‚ñà‚ñã        | 8/49 [00:11<00:51,  1.26s/it, CE1=0.866, CE2=1.782, KL=12.664, loss=3.9193]Epoch 1:  18%|‚ñà‚ñä        | 9/49 [00:11<00:52,  1.31s/it, CE1=0.866, CE2=1.782, KL=12.664, loss=3.9193]Epoch 1:  18%|‚ñà‚ñä        | 9/49 [00:12<00:52,  1.31s/it, CE1=1.109, CE2=2.437, KL=9.617, loss=4.5130] Epoch 1:  20%|‚ñà‚ñà        | 10/49 [00:12<00:50,  1.29s/it, CE1=1.109, CE2=2.437, KL=9.617, loss=4.5130]Epoch 1:  20%|‚ñà‚ñà        | 10/49 [00:13<00:50,  1.29s/it, CE1=1.003, CE2=1.689, KL=9.688, loss=3.6658]Epoch 1:  22%|‚ñà‚ñà‚ñè       | 11/49 [00:13<00:48,  1.27s/it, CE1=1.003, CE2=1.689, KL=9.688, loss=3.6658]Epoch 1:  22%|‚ñà‚ñà‚ñè       | 11/49 [00:14<00:48,  1.27s/it, CE1=0.949, CE2=2.279, KL=7.656, loss=3.9992]Epoch 1:  24%|‚ñà‚ñà‚ñç       | 12/49 [00:14<00:44,  1.21s/it, CE1=0.949, CE2=2.279, KL=7.656, loss=3.9992]Epoch 1:  24%|‚ñà‚ñà‚ñç       | 12/49 [00:16<00:44,  1.21s/it, CE1=1.309, CE2=2.708, KL=9.172, loss=4.9384]Epoch 1:  27%|‚ñà‚ñà‚ñã       | 13/49 [00:16<00:43,  1.22s/it, CE1=1.309, CE2=2.708, KL=9.172, loss=4.9384]Epoch 1:  27%|‚ñà‚ñà‚ñã       | 13/49 [00:17<00:43,  1.22s/it, CE1=1.218, CE2=2.859, KL=8.703, loss=4.9519]Epoch 1:  29%|‚ñà‚ñà‚ñä       | 14/49 [00:17<00:42,  1.22s/it, CE1=1.218, CE2=2.859, KL=8.703, loss=4.9519]Epoch 1:  29%|‚ñà‚ñà‚ñä       | 14/49 [00:18<00:42,  1.22s/it, CE1=1.052, CE2=1.847, KL=9.312, loss=3.8353]Epoch 1:  31%|‚ñà‚ñà‚ñà       | 15/49 [00:18<00:41,  1.23s/it, CE1=1.052, CE2=1.847, KL=9.312, loss=3.8353]Epoch 1:  31%|‚ñà‚ñà‚ñà       | 15/49 [00:19<00:41,  1.23s/it, CE1=1.322, CE2=2.594, KL=9.547, loss=4.8747]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 16/49 [00:19<00:40,  1.24s/it, CE1=1.322, CE2=2.594, KL=9.547, loss=4.8747]Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 16/49 [00:21<00:40,  1.24s/it, CE1=1.096, CE2=2.021, KL=9.391, loss=4.0609]Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñç      | 17/49 [00:21<00:39,  1.24s/it, CE1=1.096, CE2=2.021, KL=9.391, loss=4.0609]Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñç      | 17/49 [00:22<00:39,  1.24s/it, CE1=1.148, CE2=2.201, KL=9.570, loss=4.3106]Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 18/49 [00:22<00:38,  1.24s/it, CE1=1.148, CE2=2.201, KL=9.570, loss=4.3106]Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 18/49 [00:23<00:38,  1.24s/it, CE1=1.195, CE2=2.199, KL=10.742, loss=4.4729]Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 19/49 [00:23<00:38,  1.29s/it, CE1=1.195, CE2=2.199, KL=10.742, loss=4.4729]Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 19/49 [00:24<00:38,  1.29s/it, CE1=1.176, CE2=2.133, KL=8.688, loss=4.1829] Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 20/49 [00:24<00:36,  1.27s/it, CE1=1.176, CE2=2.133, KL=8.688, loss=4.1829]Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 20/49 [00:25<00:36,  1.27s/it, CE1=1.274, CE2=1.147, KL=7.270, loss=3.1533]Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 21/49 [00:25<00:33,  1.21s/it, CE1=1.274, CE2=1.147, KL=7.270, loss=3.1533]Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 21/49 [00:27<00:33,  1.21s/it, CE1=1.087, CE2=1.748, KL=7.117, loss=3.5516]Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/49 [00:27<00:31,  1.16s/it, CE1=1.087, CE2=1.748, KL=7.117, loss=3.5516]Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/49 [00:28<00:31,  1.16s/it, CE1=0.828, CE2=1.030, KL=8.844, loss=2.7470]Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 23/49 [00:28<00:30,  1.18s/it, CE1=0.828, CE2=1.030, KL=8.844, loss=2.7470]Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 23/49 [00:29<00:30,  1.18s/it, CE1=1.228, CE2=1.879, KL=6.617, loss=3.7735]Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 24/49 [00:29<00:28,  1.15s/it, CE1=1.228, CE2=1.879, KL=6.617, loss=3.7735]Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 24/49 [00:30<00:28,  1.15s/it, CE1=0.869, CE2=1.318, KL=9.727, loss=3.1646]Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/49 [00:30<00:29,  1.22s/it, CE1=0.869, CE2=1.318, KL=9.727, loss=3.1646]Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/49 [00:31<00:29,  1.22s/it, CE1=1.012, CE2=1.499, KL=7.062, loss=3.2222]Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 26/49 [00:31<00:26,  1.17s/it, CE1=1.012, CE2=1.499, KL=7.062, loss=3.2222]Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 26/49 [00:33<00:26,  1.17s/it, CE1=1.029, CE2=1.278, KL=11.312, loss=3.4427]Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 27/49 [00:33<00:28,  1.29s/it, CE1=1.029, CE2=1.278, KL=11.312, loss=3.4427]